

# **常见的 IDL 示例：**

1. **Protocol Buffers (Protobuf)**：


**IDL**（**Interface Definition Language**）是一种用于定义软件系统中不同组件之间接口的语言。
IDL 主要用于在分布式系统中，特别是在 **远程过程调用（RPC）**、**微服务** 和 **跨语言通信** 等场景中，帮助系统组件之间进行数据交换和服务调用。IDL 提供了一种独立于编程语言的接口定义方式，使得不同编程语言实现的服务能够互相通信。

示例： 

一个用 Java 写的客户端可以通过 IDL 和一个用 C++ 编写的服务器进行交互。

**gRPC** 不是一个传统意义上的框架，而是一个 **高性能、开源、跨语言的远程过程调用（RPC）系统**，由 Google 开发并开源。它使得不同系统之间能够以高效、可靠的方式进行远程调用，通常用于微服务架构中进行服务间的通信。

gRPC 使用了 **Protocol Buffers（Protobuf）** 作为其接口定义语言（IDL），并且通过 HTTP/2 协议实现高效的通信。

# **gRPC 的核心特点**

1. **远程过程调用（RPC）系统**：
    
    - gRPC 允许客户端调用远程服务器上的方法，就像调用本地方法一样。它隐藏了网络通信的复杂性，简化了开发过程。
2. **使用 Protocol Buffers 作为 IDL**：
    
    - 在 gRPC 中，服务的接口和数据结构通过 **Protocol Buffers（Protobuf）** 来定义。Protobuf 是一种轻量、高效的序列化数据格式，能够在不同编程语言间传输数据。
3. **支持多种编程语言**：
    
    - gRPC 支持多种编程语言，包括 C、C++、Java、Go、Python、Ruby、PHP、C#、Node.js 等，确保在异构环境中能够实现不同语言的系统互通。
4. **高效的通信协议：HTTP/2**：
    
    - gRPC 基于 **HTTP/2** 协议，这意味着它具有许多优势：
        - **多路复用**：一个连接可以处理多个请求，减少连接建立和关闭的开销。
        - **二进制协议**：相比于 HTTP/1.x 的文本协议，HTTP/2 使用二进制协议传输数据，效率更高。
        - **流控和头部压缩**：提高网络利用率，减少延迟。
5. **支持同步和异步调用**：
    
    - gRPC 支持 **同步** 和 **异步** 调用。客户端可以选择等待服务器返回结果，也可以使用异步调用进行非阻塞操作。
6. **流式数据传输**：
    
    - gRPC 支持四种类型的 RPC：
        1. **单向调用（Unary RPC）**：客户端发送一个请求并等待一个响应。
        2. **服务器流式调用（Server Streaming RPC）**：客户端发送一个请求，服务器返回一个流式响应。
        3. **客户端流式调用（Client Streaming RPC）**：客户端发送多个请求，服务器返回一个响应。
        4. **双向流式调用（Bidirectional Streaming RPC）**：客户端和服务器可以同时发送和接收流式数据。
7. **内建的认证、负载均衡和错误处理**：
    
    - gRPC 提供了对 **认证**、**负载均衡**、**自动重试**、**流量控制**、**错误处理** 和 **服务发现** 等功能的支持，简化了分布式系统中的许多常见操作。

### **gRPC 适用场景**

- **微服务架构**：gRPC 特别适用于微服务架构中的服务间通信，能够确保高效的网络通信和低延迟。
- **跨语言服务通信**：当不同服务使用不同编程语言时，gRPC 可以帮助实现语言之间的高效通信。
- **实时通信**：由于支持双向流式通信，gRPC 适合用于实时数据流的应用，例如在线游戏、视频流、聊天应用等。
- **高性能系统**：gRPC 基于 HTTP/2 和 Protobuf，能够提供比传统 HTTP/1.x 更高效的通信，适合需要低延迟和高吞吐量的应用。

### **gRPC 与传统 RPC 框架的比较**

|特性|gRPC|传统 RPC（如 Java RMI、.NET Remoting）|
|---|---|---|
|**通信协议**|HTTP/2|HTTP/1.x 或 TCP|
|**接口定义**|使用 Protocol Buffers（Protobuf）|各种（如 XML、JSON、IDL）|
|**语言支持**|跨语言支持（C、C++、Java、Go、Python、Node.js 等）|主要针对特定语言（如 Java、.NET）|
|**流式通信**|支持（单向、双向流式调用）|大多不支持|
|**性能**|高效（二进制协议，HTTP/2 多路复用）|性能较低|
|**负载均衡与重试**|内建支持|需要外部库或框架支持|
|**安全性**|内建支持（TLS 加密、认证）|需要外部实现|

### **gRPC 与 REST API 的区别**

1. **通信协议**：
    
    - gRPC 使用 **HTTP/2** 协议，而 REST 通常使用 **HTTP/1.x**。HTTP/2 提供了更高效的多路复用、头部压缩等功能。
2. **数据格式**：
    
    - gRPC 使用 **Protocol Buffers（Protobuf）** 作为默认的数据序列化格式，它是一种二进制格式，效率高且体积小。REST 通常使用 **JSON** 格式，它易于阅读但相对较重。
3. **性能**：
    
    - gRPC 因为使用二进制协议和 HTTP/2，通常比 REST 更高效，适合用于高吞吐量、低延迟的应用场景。
4. **消息传输模式**：
    
    - gRPC 支持 **双向流式通信**，而 REST 通常是 **请求-响应模式**。
5. **适用场景**：
    
    - REST 更适合 Web 应用和客户端-服务器模式，尤其是与浏览器交互时。gRPC 更适合于服务间高效通信、微服务架构、实时数据流等场景。

### **总结**

gRPC 是一个高效、跨语言的远程过程调用系统，提供了高性能、低延迟的通信机制，广泛应用于微服务架构和分布式系统中。与传统的 RPC 框架相比，gRPC 通过 HTTP/2 和 Protocol Buffers 提供了更高的性能和更强的功能支持，尤其适用于跨语言服务之间的高效通信。



#  表设计


gRPC用于微服务间通信是什么意思？目前我只是了解就是可以通过proto文件将RESTFUL API转换为gRPC可用的接口，你看我这个理解对吗？但是在日常的生活中大多数用户也都是通过http请求来请求服务的？所以我还是不太明白这个gRPC是什么作用


你的理解已经很接近了，但可以再深入一点。

### gRPC 用于微服务间通信是什么意思？

在微服务架构中，系统通常被拆解为多个独立的服务，每个服务负责特定的功能。这些服务需要进行通信，通常有两种方式：

- **HTTP/RESTful API**：这是最常见的方式，客户端通过 HTTP 协议向服务发送请求，并获取响应。
- **gRPC**：是基于 HTTP/2 和 Protocol Buffers 的一种远程过程调用（RPC）协议。

### 你的理解

你理解的确实有一部分是对的。gRPC 通过 `.proto` 文件来定义服务接口，使用 Protocol Buffers 来序列化和反序列化数据，这样可以将传统的 RESTful API 转换为 gRPC 的接口。但区别在于，gRPC 不是直接将 RESTful API 转换成 gRPC，而是提供了一个更高效的、基于 HTTP/2 的通信协议。

### gRPC 和 HTTP 的区别

- **HTTP/1 vs HTTP/2**：gRPC 使用 HTTP/2，这比传统的 HTTP/1 更加高效，支持流控制、头部压缩和多路复用，可以减少延迟，提高吞吐量。
- **协议**：RESTful API 通常基于 JSON 格式来传输数据，使用的是 HTTP 协议，而 gRPC 使用 Protocol Buffers（proto 文件定义）作为数据传输格式，速度更快，数据包体积更小。
- **请求/响应**：HTTP API 通常是单次的请求-响应模式，而 gRPC 支持多种通信方式，包括请求-响应、单向流和双向流等。

### gRPC 在微服务中的作用

1. **高效通信**：gRPC 使用二进制协议，比 JSON 更小，性能更好，特别适合高频次的微服务之间的通信。
2. **多语言支持**：gRPC 支持多种语言，可以实现跨语言的微服务通信，服务间的调用更为灵活。
3. **更丰富的功能**：gRPC 支持流式数据、双向通信、内建的负载均衡、超时控制等高级特性。

### 日常用户请求与微服务之间的关系

虽然用户通过 HTTP 请求来访问服务，但这些请求背后可能涉及到微服务间的内部通信。如果你有一个前端请求，需要处理用户登录，后端可能会调用多个微服务来完成认证、权限验证、数据查询等。此时，微服务之间通常会使用 gRPC 进行高效的内部通信，而前端和用户的请求通常还是通过 HTTP 来处理的。

简而言之，**gRPC 主要用于微服务间的通信**，它让服务之间的请求更高效、可靠，并且更适合分布式系统。而对于外部用户，仍然可以通过 HTTP 来交互。



## 注册中心用在什么层，作用是什么？

注册中心一般用于 **服务发现层**，它的作用是管理和追踪系统中的所有服务实例，使得客户端能够在运行时动态地找到服务。

# 注册中心的作用：

1. **服务注册**：服务启动时会将自己的信息（如地址、端口、健康检查等）注册到注册中心。
2. **服务发现**：客户端可以从注册中心获取某个服务的可用实例，支持动态发现服务的地址。
3. **负载均衡**：注册中心与负载均衡结合，帮助将流量分发到多个服务实例。
4. **故障转移**：如果某个服务实例宕机，注册中心可以从可用实例列表中移除该实例，客户端可以自动切换到其他健康实例。

### 举个例子：

假设你有一个电商系统，其中有多个微服务，例如用户服务、商品服务、订单服务等。每个服务都有多个实例来承载流量。当这些服务启动时，它们会向注册中心（如 **Consul**）注册自己的信息。这样，其他服务或客户端就可以通过查询注册中心来找到它们。

例如：

- **用户服务**（User Service）在启动时会将自己的 IP 和端口注册到 Consul。
- 当 **订单服务**（Order Service）需要调用 **用户服务** 时，它不会直接访问某个特定 IP 和端口，而是查询注册中心，获取到 **用户服务** 的可用实例信息。
- 如果某个 **用户服务** 实例宕机，注册中心会自动移除这个实例，**订单服务** 只会从健康的实例中选择连接。

### 典型的工作流程：

1. **服务注册**：服务启动后向注册中心注册自己的 IP、端口、健康检查等信息。
2. **服务发现**：其他服务在调用时查询注册中心获取目标服务的地址。
3. **负载均衡**：注册中心返回多个实例时，客户端可以使用负载均衡策略（如轮询、随机等）选择一个实例进行通信。
4. **故障转移**：当某个实例不可用时，客户端会自动从注册中心获取可用实例。

### 使用场景：

假设你有一个用户服务（User Service）和订单服务（Order Service），它们都部署在 Kubernetes 上。用户服务可能会动态扩缩容，增加或减少实例。如果没有注册中心，订单服务就无法知道当前可用的用户服务实例。而注册中心可以帮助订单服务动态发现最新的用户服务实例，确保调用时连接的是健康且可用的服务实例。****


### 举个例子：

假设：

- **用户服务** 有 3 个实例：`user-service-1`, `user-service-2`, `user-service-3`，它们的地址可能是 `10.0.0.1:8080`, `10.0.0.2:8080`, `10.0.0.3:8080`。
- 用户服务会在启动时向注册中心（如 Consul）注册自己，例如将 `user-service-1` 的信息注册为 `10.0.0.1:8080`，`user-service-2` 注册为 `10.0.0.2:8080`，`user-service-3` 注册为 `10.0.0.3:8080`。

### 订单服务的流程：

1. **订单服务调用用户服务**：当订单服务需要获取用户信息时，它并不直接知道用户服务的实例地址。它查询注册中心，获取到当前所有可用的用户服务实例（比如，`10.0.0.1:8080`，`10.0.0.2:8080`，`10.0.0.3:8080`）。
    
2. **负载均衡**：订单服务根据负载均衡策略选择一个实例（比如轮询、随机等），并向 `10.0.0.1:8080` 发起请求。
    
3. **实例变化**：假设某个实例 `10.0.0.1:8080` 宕机了，注册中心会将其从可用实例列表中移除。订单服务在下次查询时不会看到 `10.0.0.1:8080`，而是会看到其他健康的实例。
    
4. **动态发现**：订单服务每次发起请求时，都是通过注册中心查询到最新的、健康的用户服务实例，不需要手动配置具体的服务地址。
    

### 总结：

“订单服务发现用户服务”是指订单服务不直接依赖硬编码的用户服务地址，而是通过注册中心动态查找和连接到可用的用户服务实例。这样即使用户服务的实例发生变化，订单服务也能够自动适应，保证系统的可靠性和灵活性。



**DNS 查询** 和 **HTTP 查询** 都是网络通信中常见的查询方式，但它们的用途和实现方式不同。

# 1. **DNS 查询**

DNS（Domain Name System，域名系统）是一种将**域名**（例如 `www.example.com`）转换为**IP 地址**的系统。因为人类更容易记住域名，而计算机则使用 IP 地址进行通信。

**DNS 查询** 是指客户端通过 DNS 服务查询某个域名对应的 IP 地址，从而找到目标主机并进行通信。

#### 举个例子：

假设你访问 `www.google.com`，计算机并不直接知道 `www.google.com` 对应的 IP 地址。它会通过 DNS 查询，将 `www.google.com` 转换成一个 IP 地址（比如 `172.217.5.68`），然后才能与该 IP 地址上的服务器建立连接。

**作用**：DNS 解决了人类易记的域名与计算机通信所需的数字化 IP 地址之间的转换。

**使用场景**：

- **服务发现**：在微服务架构中，如果每个服务都被分配了一个域名（如 `user-service.example.com`），那么服务间可以通过 DNS 查询对方的 IP 地址来进行通信。
- **负载均衡**：某些服务通过 DNS 解析可以获得多个 IP 地址，从而实现流量的负载均衡。

# 2. **HTTP 查询**

HTTP（Hypertext Transfer Protocol，超文本传输协议）是 **应用层协议**，主要用于客户端（如浏览器或其他应用）与服务器之间的通信。当客户端想请求某些资源（如网页、数据、文件等）时，通常会通过 HTTP 协议发送请求。

**HTTP 查询** 指的就是通过 **HTTP 协议向服务器发起请求，获取所需的资源或执行某些操作。**

#### 举个例子：

- 当你在浏览器中输入 `https://www.google.com` 时，浏览器会通过 HTTP/HTTPS 协议向 Google 服务器发送请求，查询该 URL 对应的页面或资源。
- 如果是 **API 请求**，比如你调用 `GET /users/123` 获取用户信息，实际上是通过 HTTP 向服务端发送一个 HTTP GET 请求。

**作用**：HTTP 查询用于客户端和服务器之间的通信，获取资源、数据或者执行操作。

**使用场景**：

- **Web 页面加载**：浏览器通过 HTTP 请求获取网页内容。
- **API 调用**：在微服务架构中，一个服务可能会通过 HTTP 请求（例如 RESTful API）调用另一个服务，获取数据或执行操作。

### 对比：

- **DNS 查询**：用于将域名解析为 IP 地址，主要解决**如何找到服务**的问题。
- **HTTP 查询**：用于客户端与服务器之间的具体数据交互，主要解决**如何获取或操作数据**的问题。

### 结合使用的例子：

在微服务架构中，**DNS 查询** 和 **HTTP 查询** 常常结合使用：

- 服务注册到注册中心（比如 Consul 或 Eureka）时，可能会使用域名（例如 `user-service.local`）。
- 当另一个服务需要调用 **用户服务** 时，它会通过 DNS 查询解析 `user-service.local` 到实际的 IP 地址，然后通过 HTTP 协议向该服务发送请求。

这使得服务之间的通信既能够支持动态的地址变更（通过 DNS 解析），又能够高效地进行数据交互（通过 HTTP 请求）。



### 举个例子：

假设你有一个 **电商系统**，该系统包括用户服务、商品服务、订单服务等。每个服务会在启动时向 etcd 注册自己的 IP 地址和端口，并提供健康检查信息。其他服务通过查询 etcd 来发现并连接到用户服务、订单服务等。

如果某个服务实例宕机，etcd 会及时将其从可用实例列表中移除，其他服务将自动获取最新的健康实例信息，确保整个系统的可靠性。

### 总结：

- **etcd** 是一个高可用、分布式的键值存储系统，广泛用于服务发现、配置管理、分布式锁等场景。
- 它使用 **Raft 协议** 来确保分布式系统中的数据一致性，是构建现代分布式应用（如微服务架构和容器化平台）时的关键组件。


- - 传统注册中心如 Eureka 和 Consul 也提供服务发现功能，但通常不具备像 etcd 那样的强一致性保障。它们可能通过最终一致性模型来确保数据同步，而 etcd 提供强一致性。




# K/V存储


**K/V 存储能达到高效、可扩展、高可用等效果**，主要是因为它的设计理念简单、操作直接，且采用了一些非常高效的数据结构和技术。以下是为什么 K/V 存储能够达到这些效果的几个关键原因：

### 1. **简单的数据模型**

K/V 存储的核心是一个简单的 **键值对** 结构：

- **键**（Key）是唯一的标识符。
- **值**（Value）是与键关联的数据，可以是简单的数据类型、对象、文件等。

这种简单性使得 K/V 存储能够优化存储和查询操作，减少了复杂的数据库架构所带来的性能开销。由于没有复杂的表结构、关系型查询和事务等功能，K/V 存储能够快速响应并高效执行操作。

### 2. **高效的数据结构**

大多数 K/V 存储系统使用 **哈希表**（Hash Table）或者 **B树/B+树** 等数据结构来存储键值对，这些结构能够提供：

- **O(1) 平均时间复杂度**：在哈希表中，键值对的查找、插入和删除操作都可以在常数时间内完成，极大提高了数据操作的效率。
- **有序存储**（例如 B 树和 B+ 树）：对于需要按顺序遍历或范围查询的场景，B 树提供了很好的性能，它保证了键的有序性，并能以对数时间（O(log n)）进行插入和查找。

这些高效的数据结构是 K/V 存储能提供快速读写的基础。

### 3. **分布式架构与横向扩展**

K/V 存储通常设计为 **分布式系统**，支持横向扩展（scale out），可以在多个节点之间分布数据。这种架构使得系统可以随业务增长而扩展。通过 **分片（sharding）** 和 **数据复制（replication）**，K/V 存储能够高效地分配和存储大量数据，同时保持高可用性和一致性。

- **分片**：将数据划分为多个小部分，每个部分由不同的节点存储，允许数据分布在多个节点上，减少单个节点的压力。
- **复制**：每个数据分片可以有多个副本，分布在不同的节点上，这样即使某个节点宕机，数据也不会丢失，且系统能够继续提供服务。

这种分布式架构使得 K/V 存储系统在处理大规模数据时，不仅能够提供高效的存取速度，而且具备较强的容错能力和扩展能力。

### 4. **高并发支持**

K/V 存储通常设计成支持高并发的环境。由于其简单的数据模型和高效的数据结构，K/V 存储能够同时处理大量的并发请求。这对于需要快速响应的应用（如缓存、会话存储等）非常重要。

很多 K/V 存储系统（如 **Redis**）采用了 **单线程** 或者 **多线程池** 的方式，优化了并发访问。通过 **事件驱动** 和 **非阻塞 IO**，它们能够在同一时刻处理多个客户端请求，并保持响应速度。

### 5. **一致性和高可用性保障**

- **一致性**：K/V 存储中的大部分系统（例如 **etcd**）使用分布式一致性协议，如 **Raft** 协议来保证数据的一致性。Raft 确保了所有节点对数据的视图是同步的，避免了数据不一致的问题，保障了强一致性。
    
    即使某个节点发生故障，Raft 协议也能通过选举机制选出新的领导者节点，并恢复系统的正常运行，确保数据的一致性。
    
- **高可用性**：分布式复制技术确保了即使某些节点失效，系统依然能够提供服务。数据在多个节点间的冗余存储能够保证在节点宕机时依然能够从其他副本读取数据，从而实现系统的高可用性。
    

### 6. **轻量级与无模式（Schema-less）**

K/V 存储系统通常是 **无模式** 的，这意味着你不需要为数据设计复杂的结构（如关系型数据库的表结构）。每个键值对都可以存储任意类型的数据，从而提升了存储的灵活性和扩展性。

这种设计使得 K/V 存储非常适合处理各种不同类型的数据（如字符串、JSON、二进制文件等），并且减少了管理数据模式所带来的额外开销。

### 7. **数据持久化与容灾恢复**

虽然 K/V 存储的核心优势在于 **内存存储**，许多系统（如 **Redis**、**etcd**）也提供 **持久化机制**，确保数据即使在重启或故障后依然可恢复。常见的持久化机制有：

- **快照（RDB）**：定期将内存数据快照到磁盘，保证数据持久化。
- **追加文件（AOF）**：记录所有写操作日志，系统重启时可以通过日志恢复数据。

这些持久化机制既能保证数据丢失最小化，又能保持高速读写性能。

### 总结：为什么 K/V 存储能达到高效、高可用的效果？

1. **简单高效的设计**：通过键值对存储，简化了数据结构，优化了查询、更新操作。
2. **高效的数据结构**：使用哈希表、B树等高效数据结构，保证了数据的快速访问。
3. **分布式架构**：通过分片、复制和横向扩展，支持大规模数据的存储和管理。
4. **高并发支持**：K/V 存储能够同时处理大量并发请求，适应高流量场景。
5. **一致性与高可用性**：通过一致性协议和复制机制，保证数据一致性和系统的高可用性。
6. **灵活性与扩展性**：无模式设计和灵活的数据存储形式使得 K/V 存储适应各种应用需求。

这些特点使得 K/V 存储非常适合用于高效的数据存取、服务发现、缓存、配置管理等场景。

#### 本质区别：

K/V 存储系统的操作通常非常简单：**键（Key）查找对应的值（Value）**。由于数据模型非常简单，不涉及复杂的 **联合查询**、**事务** 或 **数据关系**，K/V 存储能够以更少的计算量和更低的延迟响应请求。相较于需要执行复杂查询、涉及多个表的数据库，K/V 存储的单一操作模型让它能够在高并发环境下高效处理大量的请求。


#### 为什么别的存储不容易高并发？

- **关系型数据库（RDBMS）**：大多数传统关系型数据库（如 MySQL、PostgreSQL）会在执行查询时涉及多个表的连接、索引查找、排序等操作，这些操作非常消耗 CPU 和内存，特别是当请求量大时，数据库需要锁机制（行锁、表锁等）来保证数据的一致性。这样会导致性能瓶颈，尤其在高并发情况下，锁的竞争可能造成 **性能下降** 和 **延迟增加**。
- **NoSQL 数据库**（如 MongoDB、Cassandra）：虽然它们比关系型数据库在并发处理上表现更好，但它们的复杂查询、写入分布式数据以及需要保证一致性的分布式协议（如 CAP 定理）也会带来一定的性能瓶颈，尤其是在需要同步的数据更新操作上。


许多 K/V 存储系统（如 **Redis**）将数据存储在内存中，而不是磁盘上。内存存储的访问速度远远高于磁盘存储，因为：

- 内存访问延迟通常比硬盘低几个数量级。
- 内存的读写速度可以达到每秒数百万次，而磁盘则可能只有几千次。

这样，K/V 存储系统能够快速响应大量并发请求，减少磁盘I/O带来的延迟。


# 1. **I/O 多路复用**（I/O Multiplexing）

- **背景**：在传统的 **同步阻塞 I/O** 模型中，当一个程序发起 I/O 操作（如读取文件、网络请求等）时，程序会被 **阻塞**，直到 I/O 操作完成才会继续执行。比如，如果有多个连接，每个连接都需要等待其 I/O 操作完成，这就导致了性能的低效。
    
- **I/O 多路复用** 是一种技术，它允许 **一个线程** 或 **一个进程** 在同一时刻同时监听多个 I/O 通道（例如多个网络连接），并在有 **可读写数据** 时才进行处理，避免了线程被阻塞。
    
- 这就是所谓的 **“多路复用”**，即通过一个线程或进程来“复用”多个 I/O 通道，而无需为每个 I/O 操作创建新的线程或进程。常见的技术有 `select`、`poll`、`epoll`（Linux）等。

示例： 

想象你有多个网络连接，每个连接都在等待数据的到来。传统方式是为每个连接创建一个线程，阻塞等待数据。但通过 **I/O 多路复用**，你只需要一个线程监听所有连接的状态，只有当有数据到达时才会去处理，极大提高了效率。****

对比传统：

假设一个 Web 服务器要同时处理 1000 个客户端请求。传统的做法是为每个请求创建一个线程。假如每个线程都需要等待某个数据库的查询结果（例如数据库操作会导致阻塞），那么这些线程就会被 **阻塞**，即使它们什么也不做，仍然会占用系统的内存和 CPU 时间。随着连接数增多，系统会变得越来越慢，甚至崩溃。




# 2. **非阻塞 I/O 操作**

- **阻塞 I/O**：当你发起一个 I/O 操作时，如果数据未准备好，操作会被阻塞，程序会等待直到数据准备完毕。这在高并发场景下非常低效，因为每个 I/O 操作都需要等待完成，无法利用空闲的时间去处理其他任务。
    
- **非阻塞 I/O**：与阻塞 I/O 相反，非阻塞 I/O 操作在执行时不会阻塞线程。如果数据还未准备好，操作会立即返回，程序可以继续执行其他任务。它允许程序更高效地处理多个 I/O 操作，而不需要等待每个 I/O 操作完成。
    

#### 举个例子：

你发起一个网络请求，如果服务器没有及时响应，**非阻塞 I/O** 操作会立即返回，让程序继续做其他事（例如处理其他请求），而不是等待服务器响应。


# 疑问：

I/O多路复用如何实现？

这里面用到了什么数据结构吗？ 如果A先发起了请求在等待中然后去处理B的请求，当A的请求到达后，并处理完成后，还会继续处理B的请求吗？还有在后续处理A的过程中，B处在等待的过程中，有可能其他的服务去处理B吗？B在发送请求到A后，它在等待的过程中还会发送请求吗？


# 解答：

2. **如果 A 请求发起了并在等待中，处理 B 的请求后，A 的请求完成后，还会继续处理 B 吗？**

**A** 的请求和 **B** 的请求是两个独立的 I/O 操作。当 A 的请求进入等待状态后（比如等待数据库查询或等待网络响应），服务器会继续处理 B 的请求，甚至是 C、D 等其他请求。

- **当 A 的请求到达后**，服务器会接到通知，处理 **A** 的请求。
- **在处理 A 请求时**，如果 B 的请求仍然在等待状态，那么此时 B 并不会被继续处理，除非 B 的请求也准备好了。
- 处理完成 A 的请求后，服务器会继续处理下一个在等待队列中有数据准备好的请求（比如 B 的请求，如果它的数据已经准备好了）。

可以理解为 **事件驱动**，服务器并不会直接按顺序处理 A、B 请求，而是看哪个请求的 I/O 操作准备好了，哪个就被处理。


 3. **在后续处理 A 的过程中，B 在等待时，是否有可能其他服务去处理 B？**

**B 的请求**一般会在服务器端的同一线程中等待，除非采取了 **分布式架构** 或 **负载均衡**，否则通常不会有其他服务去处理 B。B 依然在等待队列中，直到 I/O 多路复用机制通知服务器有数据准备好，才会继续处理。

但是，在分布式场景下，B 的请求有可能会被路由到 **其他节点** 或 **服务实例** 去处理。例如，微服务架构中，某个请求可能会被负载均衡到另一个服务实例处理。

 4. **B 在发送请求到 A 后，它在等待的过程中是否会发送请求？**

是的，**B** 可以继续发送请求到 **其他服务**。I/O 多路复用的特点是 **非阻塞**，也就是说，B 在等待 A 的响应时，它可以继续进行其他 I/O 操作，甚至发送新的请求到其他服务。

例如：

- **B** 在等待 A 的响应时，可能会继续向其他服务发起请求。
- **B** 可以处理自己的其他任务，或继续等待其他 I/O 操作。

这种 **并发** 和 **非阻塞** 的机制让多个请求可以并行进行，而每个请求不会阻塞其他请求的进程。  


# 软硬编码：

硬编码和软编码的区别在于：硬编码将具体数值、参数等直接写入程序代码中，缺乏灵活性，不易修改和维护；软编码通过变量、配置文件等方式将数值或参数抽象出来，使得程序更具灵活性，易于修改和维护

# 管理项目配置文件：

1. 环境变量：.env K8s_env

	加载.env文件到环境变量中


3. 配置文件： Json Yaml等

4. 配置中心：Consul etcd

- 配置中心需要独立的部署和运维。
- 存在单点故障的风险，需考虑高可用性设计


# 分布式存储

**分布式存储相较于原始存储提升了：**

1. **扩展性**：能够处理海量数据，并动态扩展。
2. **高可用性**：通过冗余和副本机制，保障数据的可靠性。
3. **性能**：负载均衡、并行处理提升了并发性能。
4. **灵活性和容灾能力**：支持灵活部署，具有容灾和恢复能力。
5. **成本优化**：通过分布式部署和廉价硬件，降低成本。
6. **数据管理**：高效的分片和索引机制提升了数据管理效率。

分布式存储使得大规模数据处理变得更加高效、可靠和经济，是现代大数据、云计算和高并发应用系统的基础。

假设你在做一个社交平台的后台存储系统，用户每天上传大量的图片和视频，数据量快速增加。

- **传统存储**：你只能使用一台机器来存储这些数据。随着数据量的增加，单机硬盘存储能力达到瓶颈，可能导致存储满了，或者存取数据的速度变慢，用户访问的响应时间增加。同时，如果这台机器发生故障，可能导致大量数据丢失，且恢复困难。
    
- **分布式存储**：你使用分布式存储系统，如 HDFS 或 Ceph，将这些图片和视频分布存储在多台机器上。这些机器可能分别位于不同的数据中心，数据会自动分片存储，并且为每个数据块创建多个副本。即使某台机器出现故障，其他副本也能保证数据不丢失，同时系统可以动态扩展，新增机器以应对更大的存储需求。


# 分布式存储的数据分片和副本机制，不是增加了难度吗

分片策略：分片是根据一定的规则将数据分配到不同的节点上。常见的分片策略有：
范围分片（Range Sharding）：按数据的某个字段（通常是 ID 或时间）划分范围，将数据范围分配到不同的节点。例如，ID 1-1000 存储在 Node 1，1001-2000 存储在 Node 2。
哈希分片（Hash Sharding）：通过哈希函数计算字段值（如用户 ID）的哈希值，然后根据哈希值将数据均匀地分配到不同的节点上。例如，哈希值为 0 的数据存储在 Node 1，哈希值为 1 的数据存储在 Node 2。
复合分片（Composite Sharding）：结合多个字段的值来分片，比如先按地理位置分片，再按时间分片。

- **高吞吐量**：每个节点只处理自己分片的数据，减轻了单节点的负担，提升了系统的并发性能。
- **水平扩展性**：当数据量增长时，可以通过增加节点来扩展系统，避免了单节点存储瓶颈。

#### 挑战：

- **跨分片查询**：当数据分布在多个节点上时，某些查询可能涉及多个分片，需要跨节点进行查询，这会增加系统的复杂度和延迟。
- **分片迁移**：随着数据的不断增长，可能需要重新分配分片。如何平滑地迁移分片，保证系统的高可用性是一个挑战。‘

### 2. **副本机制（Replication）**

副本机制是指将数据复制到多个节点上，以提高系统的容错性和可用性。副本机制确保了即使某个节点或数据中心出现故障，数据依然能够通过其他副本恢复。

#### 实现方式：

- **主从复制（Master-Slave Replication）**：在这种方式中，数据的写操作只会在**主节点**上进行，而读操作可以从**从节点**进行。每当主节点的数据发生变更时，会将变更同步到从节点。典型的数据库如 MySQL 就采用了这种方式。
- **多主复制（Multi-Master Replication）**：在多主复制中，多个节点都可以接收读写请求，数据会在这些节点之间进行同步。此方式适用于需要高可用性和低延迟的系统，但会带来同步冲突的问题。


**同步与异步复制**：

- **同步复制**：每次写入都需要等待所有副本节点完成写入后再返回响应。保证了数据一致性，但会增加延迟。
- **异步复制**：写入操作完成后直接返回响应，副本节点会在后台异步同步数据。这样可以提高性能，但在极端情况下可能会导致数据不同步（如节点故障后）。


# 编码指南


Style Guide
https://github.com/uber-go/guide/blob/master/style.md

https://protobuf.dev/programming-quides/style/


1. 自定义错误码：

错误码结构：

系统编码： 子系统，业务编码，数据校验错误，权限不足，接口操作（细化错误码哪里出问题）

错误码文档：

统一错误码命名和规范（http错误保持协调）

简洁 易于理解，拓展

错误描述清楚 code： message：

2. 日志风格：

打印日志：重要信息，问题，原因，
trace id 链路追踪 日志库 不要泄露敏感信息 邮箱等

3. 提交规范 版本规范

Conventional Commits

https://www.conventionalcommits.org/en/v1.0.0/

# 微服务之间通信

1. RPC
Kitex（支持 gRPC Thrift）（支持的功能多）， rpc info
![[Kitex.png]]
2. RESTful API

3. Message Middleware

Kitex支持中间件： 

https://github.com/kitex-contrib/

自定义中间件：

在请求前后请求后执行一些逻辑：例如权限校验

# 微服务架构


### 架构概述

- **南北向流量（North-South Traffic）**：指的是外部客户端（比如用户浏览器、移动端应用等）向你的系统（API Gateway）发送请求。这类流量通常是 **HTTP/HTTPS 请求**，并且涉及到从外部访问你的服务。API Gateway 作为统一入口，处理来自客户端的请求并将请求路由到具体的微服务。
    
- **东西向流量（East-West Traffic）**：指的是微服务之间的内部通信。这里使用 **gRPC** 作为微服务之间的通信协议。gRPC 是一种高效、跨语言的 RPC（远程过程调用）框架，适合在微服务架构中进行高效的数据交换。


### 架构场景

1. **客户端请求**：
    
    - 客户端（如 Web 前端或移动端应用）通过 HTTP 或 HTTPS 向 **API Gateway** 发送请求。
    - 请求可以是登录请求、获取数据请求等。
2. **API Gateway**：
    
    - **API Gateway** 作为所有客户端请求的入口，负责流量的管理。它会将收到的请求分发到对应的微服务。
    - API Gateway 可能会做一些额外的处理，比如 **身份验证、授权、限流、日志记录等**。
    - 对于南北向流量，API Gateway 处理的是客户端与微服务之间的 HTTP 请求。


**微服务**：

- 系统由多个微服务组成，每个微服务负责一部分业务逻辑。例如：用户服务、商品服务、订单服务等。
- 微服务之间并不是通过 HTTP 进行通信，而是通过 **gRPC** 协议来进行通信。gRPC 提供高效的二进制数据交换，适合内部服务之间的高效调用。


**gRPC 通信**：

- 微服务之间的 **东西向流量** 使用 gRPC 进行交互，gRPC 提供了强类型的接口和高效的序列化方式，特别适用于需要高性能的分布式系统。
- 微服务调用彼此的 API，可能会查询数据、发起事务等。比如，订单服务可能会通过 gRPC 向库存服务查询商品库存。


















## 为了解决微服务的缺点，前辈们提出了下面这些概念。

### 服务注册与发现

微服务之间相互调用完成整体业务功能，如何在众多微服务中找到正确的目标服务地址，这就是所谓「[服务发现](https://zhida.zhihu.com/search?content_id=164918738&content_type=Article&match_order=1&q=%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0&zhida_source=entity)」功能。

常用的做法是服务提供方启动的时候把自己的地址上报给「服务[注册中心](https://zhida.zhihu.com/search?content_id=164918738&content_type=Article&match_order=1&q=%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83&zhida_source=entity)」，这就是「[服务注册](https://zhida.zhihu.com/search?content_id=164918738&content_type=Article&match_order=3&q=%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C&zhida_source=entity)」。服务调用方「订阅」服务变更「通知」，动态的接收服务注册中心推送的服务地址列表，以后想找哪个服务直接发给他就可以。

  

![](https://picx.zhimg.com/v2-3578297e7768e6c99d1fa1f33ebde659_1440w.jpg)

  

### [服务监控](https://zhida.zhihu.com/search?content_id=164918738&content_type=Article&match_order=1&q=%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7&zhida_source=entity)

单体程序的监控运维还好说，大型微服务架构的服务运维是一大挑战。服务运维人员需要实时的掌握服务运行中的各种状态，最好有个控制面板能看到服务的内存使用率、调用次数、健康状况等信息。

这就需要我们有一套完备的服务监控体系，包括拓扑关系、监控（Metrics）、日志监控（Logging）、调用追踪（Trace）、告警通知、健康检查等，防患于未然。

### 服务容错

任何服务都不能保证100%不出问题，生产环境复杂多变，服务运行过程中不可避免的发生各种故障（宕机、过载等等），工程师能够做的是在故障发生时尽可能降低影响范围、尽快恢复正常服务。

程序员为此避免被祭天，需要引入「[熔断](https://zhida.zhihu.com/search?content_id=164918738&content_type=Article&match_order=1&q=%E7%86%94%E6%96%AD&zhida_source=entity)、隔离、限流和降级、[超时机制](https://zhida.zhihu.com/search?content_id=164918738&content_type=Article&match_order=1&q=%E8%B6%85%E6%97%B6%E6%9C%BA%E5%88%B6&zhida_source=entity)」等「服务容错」机制来保证服务持续可用性。

### 服务安全

有些服务的[敏感数据](https://zhida.zhihu.com/search?content_id=164918738&content_type=Article&match_order=1&q=%E6%95%8F%E6%84%9F%E6%95%B0%E6%8D%AE&zhida_source=entity)存在安全问题，「服务安全」就是对敏感服务采用安全鉴权机制，对服务的访问需要进行相应的身份验证和授权，防止数据泄露的风险，安全是一个长久的话题，在微服务中也有很多工作要做。

## **服务治理**

说到「治理」一般都是有问题才需要治理，我们平常说环境治理、污染治理一个意思，微服务架构中的微服务越来越多，上面说的那些问题就更加显现，为了解决上面微服务架构缺陷「服务治理」就出现了。

  

![](https://pic3.zhimg.com/v2-238e741a39592caeb236a001013580a0_1440w.jpg)

  

微服务的那些问题都要公司技术团队自己解决的话，如果不是大型公司有成熟的技术团队，估计会很头大。幸好，有巨人的肩膀可以借给我们站上去，通过引入「微服务框架」来帮助我们完成服务治理。